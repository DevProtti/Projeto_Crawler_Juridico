import os
import logging
from typing import Tuple
from supabase import create_client, Client
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import SupabaseVectorStore
from langchain_core.documents import Document

logger = logging.getLogger(__name__)

# TODO - Montar o fluxo com Pydantic, Tavily e Craw4AI para buscar informa√ß√µes relevantes de produto e ICP da Predictus
PREDICTUS_DATA = [
    # PRODUTOS
    {"text": "Produto: Jurimetria Predictus. Software de an√°lise preditiva para prever senten√ßas e resultados de processos judiciais usando estat√≠stica.", "name": "Jurimetria"},
    {"text": "Produto: Dossi√™ Cadastral. Ferramenta de Background Check para compliance, valida√ß√£o de fornecedores e preven√ß√£o a fraudes.", "name": "Dossie Cadastral"},
    {"text": "Produto: API de Processos. Integra√ß√£o autom√°tica de dados judiciais em sistemas de terceiros via API REST.", "name": "API de Processos"},
    
    # PERSONAS
    {"text": "Persona: Diretor Jur√≠dico de Varejo. Preocupado com alto volume de processos trabalhistas e custos de indeniza√ß√£o.", "name": "Diretor Juridico Varejo"},
    {"text": "Persona: S√≥cio de Escrit√≥rio de Advocacia. Busca efici√™ncia operacional, automa√ß√£o de pe√ßas e captar grandes clientes.", "name": "Socio Advocacia"},
    {"text": "Persona: Gerente de Compliance. Focado em prevenir lavagem de dinheiro, fraudes e riscos reputacionais.", "name": "Gerente Compliance"}
]

class PredictusKB:
    def __init__(self):

        # TODO - Verificar como fazer conex√£o com o Supabase
        self.supabase_url = os.getenv("SUPABASE_URL")
        self.supabase_key = os.getenv("SUPABASE_KEY")
        
        if not self.supabase_url or not self.supabase_key:
            raise ValueError("SUPABASE_URL e SUPABASE_KEY s√£o obrigat√≥rios.")

        self.client: Client = create_client(self.supabase_url, self.supabase_key)
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        
        # --- A M√ÅGICA DO LANGCHAIN ---
        # Instanciamos o VectorStore conectado ao Supabase
        self.vector_store = SupabaseVectorStore(
            client=self.client,
            embedding=self.embeddings,
            table_name="documents",       # Nome da tabela criada no SQL
            query_name="match_documents"  # Nome da fun√ß√£o criada no SQL
        )
        
        self._ensure_populated()

    def _ensure_populated(self):
        """Verifica se o banco est√° vazio e insere os dados iniciais."""
        try:
            # Verifica√ß√£o leve usando cliente bruto
            res = self.client.table("documents").select("id", count="exact").limit(1).execute()
            
            if res.count == 0:
                logger.info("üèóÔ∏è Populando Knowledge Base via LangChain...")
                
                # Prepara documentos no formato LangChain
                docs = [
                    Document(page_content=item["text"], metadata={"name": item["name"]})
                    for item in PREDICTUS_DATA
                ]
                
                # O LangChain faz tudo: gera embedding e insere no Supabase
                self.vector_store.add_documents(docs)
                
                logger.info(f"‚úÖ {len(docs)} itens inseridos na Base de Conhecimento.")
            else:
                logger.info("üìö Knowledge Base j√° carregada.")
                
        except Exception as e:
            logger.error(f"Erro ao inicializar KB: {e}")

    def get_best_match(self, query: str) -> Tuple[str, float]:
        """
        Recebe um texto (resumo do tema) e retorna o produto/persona mais similar.
        Retorna: (Nome do Produto, Score 0-100)
        """
        # O LangChain faz o embedding da query e busca no banco
        results = self.vector_store.similarity_search_with_relevance_scores(
            query=query,
            k=1  # Queremos apenas o melhor match
        )
        
        if not results:
            return "Nenhum Match", 0.0
            
        doc, score = results[0]
        
        # O score vem normalizado (0 a 1). Multiplicamos por 100.
        return doc.metadata.get("name", "Desconhecido"), score * 100

# Inst√¢ncia Global
kb_engine = PredictusKB()